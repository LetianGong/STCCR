[Data]
dataset_name = www_WEE
max_his_period_days = 30
max_merge_seconds_limit = 3600
max_delta_mins = 1440
min_session_mins = 120
least_disuser_count = 10
least_checkins_count = 10
latN = 50
lngN = 40
split_save = 1
localGPU = 1

[Training]
use_nni = 0
mode = train
ctx = 0
regularization = 1e-5
learning_rate = 1e-4
max_epochs = 100
display_step = 1
patience = 5
train_batch = 256
val_batch = 256
test_batch = 256
save_results = 0
adv = 1
self_weight_s = 0.01
self_weight_t = 0.05
self_weight_st = 0.05
dump_path = checkpoints
rank = 0
queue_length = 2048
world_size = -1
epoch_queue_starts = 0
crops_for_assign = 01
feat_dim = 256
nmb_crops = 2
epsilon = 5.
theta = 0.95
temperature = 0.05

[Encoder]
loc_emb_size = 256
tim_emb_size = 256
uid_emb_size = 256
hidden_size = 256
num_of_rnn_layers = 2
rnn_type = GRU
time_interval_minutes = 10
dropout = 0.1

[DecoderT]
decoder_name = LogNormMix
trainable_affine = 0
n_components = 2